{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model3b\n",
    "## Ktrain Customized Regression (Text+Tabular) with BERT (API) Embeddings\n",
    "\n",
    "### TOC\n",
    "\n",
    "* [Dataset Prep](#d)\n",
    "* [Preprocessing](#p)\n",
    "* [Modeling](#m)\n",
    "    * [Model Selection](#ms)\n",
    "    * [Data Reformat](#dr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Prep <a class=\"anchor\" id=\"d\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "df_1 = pd.read_csv(\"df_model_2.csv\")\n",
    "df_1.head()\n",
    "\n",
    "#df_1['PercentChg.y']=df_1['PercentChg.y']*100\n",
    "\n",
    "#texts\n",
    "df_text = df_1[['News content', 'PercentChg.y']]\n",
    "\n",
    "x_text_prep = df_text.iloc[:, :-1].values\n",
    "y_text_prep = df_text.iloc[:, -1].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_text_train, x_text_test, y_text_train, y_text_test = train_test_split(x_text_prep, y_text_prep, \n",
    "                                                    test_size = 0.2, random_state = 123)\n",
    "\n",
    "#tabulars\n",
    "df_tab = df_1[['currentRatio', 'quickRatio', 'debtEquityRatio', 'interestCoverage',\n",
    "                   'returnOnEquity', 'priceEarningsRatio', 'receivablesTurnover', \n",
    "                   'payablesTurnover', 'eps', 'PercentChg.y']]\n",
    "\n",
    "x_tab_prep = df_tab.iloc[:, :-1].values\n",
    "y_tab_prep = df_tab.iloc[:, -1:].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tab_train, x_tab_test, y_tab_train, y_tab_test = train_test_split(x_tab_prep, y_tab_prep, \n",
    "                                                    test_size = 0.2, random_state = 123)\n",
    "\n",
    "tab_train, tab_test = train_test_split(df_tab,test_size = 0.2, random_state = 123)\n",
    "\n",
    "#tab_train = tab_train.values.tolist()\n",
    "#tab_test = tab_test.values.tolist()\n",
    "\n",
    "# to list for texts\n",
    "x_text_train = x_text_train.tolist()\n",
    "x_text_test = x_text_test.tolist()\n",
    "y_text_train = y_text_train.tolist()\n",
    "y_text_test = y_text_test.tolist()\n",
    "\n",
    "for i in range(0, len(x_text_train)): \n",
    "    x_text_train[i] = str(x_text_train[i]) \n",
    "for i in range(0, len(x_text_test)): \n",
    "    x_text_test[i] = str(x_text_test[i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing <a class=\"anchor\" id=\"p\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text\n",
    "\n",
    "trn_text, val_text, preproc_text = text.texts_from_array(x_train=x_text_train, y_train=y_text_train,\n",
    "                                          x_test=x_text_test, y_test=y_text_test,\n",
    "                                          preprocess_mode = 'bert',\n",
    "                                          maxlen=300, \n",
    "                                          max_features=35000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import tabular\n",
    "\n",
    "trn_tab, val_tab, preproc_tab = tabular.tabular_from_df(tab_train, \n",
    "                                                        label_columns=['PercentChg.y'],\n",
    "                                                        val_df=tab_test,\n",
    "                                                        is_regression=True, \n",
    "                                                        random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling <a class=\"anchor\" id=\"m\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selection <a class=\"anchor\" id=\"ms\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text = text.text_regression_model('bert', train_data = trn_text, \n",
    "                                        preproc = preproc_text, metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tab = tabular.tabular_regression_model('mlp', trn_tab, metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_out = keras.layers.concatenate([model_tab.output, model_text.output])\n",
    "merged_out = keras.layers.Dropout(0.25)(merged_out)\n",
    "merged_out = keras.layers.Dense(1000, activation='relu')(merged_out)\n",
    "merged_out = keras.layers.Dropout(0.25)(merged_out)\n",
    "merged_out = keras.layers.Dense(500, activation='relu')(merged_out)\n",
    "merged_out = keras.layers.Dropout(0.5)(merged_out)\n",
    "merged_out = keras.layers.Dense(1)(merged_out)\n",
    "\n",
    "combined_model = keras.Model([model_tab.input] + [model_text.input], merged_out)\n",
    "combined_model.compile(loss='mae', optimizer='adam', metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Reformatting for Modeling <a class=\"anchor\" id=\"d\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn_text_a,trn_text_b = [ [individualArray] for individualArray in trn_text[0]] \n",
    "#val_text_a,val_text_b = [ [individualArray] for individualArray in val_text[0]] \n",
    "trn_text_1 = trn_text[0]\n",
    "val_text_1 = val_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_text_a = trn_text_1[0]\n",
    "trn_text_b = trn_text_1[1]\n",
    "\n",
    "val_text_a = val_text_1[0]\n",
    "val_text_b = val_text_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(ktrain.SequenceDataset):\n",
    "    def __init__(self, x, y, batch_size=32, shuffle=True):\n",
    "        # error checks\n",
    "        err = False\n",
    "        if type(x) == np.ndarray and len(x.shape) != 2: err = True\n",
    "        elif type(x) == list:\n",
    "            for d in x:\n",
    "                if type(d) != np.ndarray or len(d.shape) != 2:\n",
    "                    err = True\n",
    "                    break\n",
    "        else: err = True\n",
    "        if err:\n",
    "            raise ValueError('x must be a 2d numpy array or a list of 2d numpy arrays')\n",
    "        if type(y) != np.ndarray:\n",
    "            raise ValueError('y must be a numpy array')\n",
    "        if type(x) == np.ndarray:\n",
    "            x = [x]\n",
    "\n",
    "        # set variables\n",
    "        super().__init__(batch_size=batch_size)\n",
    "        self.x, self.y = x, y\n",
    "        self.indices = np.arange(self.x[0].shape[0])\n",
    "        self.n_inputs = len(x)\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    # required for instances of tf.keras.utils.Sequence\n",
    "    def __len__(self):\n",
    "        return math.ceil(self.x[0].shape[0] / self.batch_size)\n",
    "\n",
    "    # required for instances of tf.keras.utils.Sequence\n",
    "    def __getitem__(self, idx):\n",
    "        inds = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = []\n",
    "        for i in range(self.n_inputs):\n",
    "            batch_x.append(self.x[i][inds])\n",
    "        batch_y = self.y[inds]\n",
    "        return tuple(batch_x), batch_y\n",
    "\n",
    "    # required for instances of ktrain.Dataset\n",
    "    def nsamples(self):\n",
    "        return self.x[0].shape[0]\n",
    "\n",
    "    #required for instances of ktrain.Dataset\n",
    "    def get_y(self):\n",
    "        return self.y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:  np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MyCustomDataset([x_tab_train] +  [trn_text_a] + [trn_text_b], trn_text[1], shuffle=True)\n",
    "val_data = MyCustomDataset([x_tab_test] + [val_text_a] + [val_text_b], val_text[1], shuffle=False)\n",
    "learner = ktrain.get_learner(combined_model, train_data=train_data, val_data=val_data, batch_size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 0.001...\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 83s 17s/step - loss: 0.0424 - mae: 0.0424 - mse: 0.0038 - val_loss: 0.0163 - val_mae: 0.0163 - val_mse: 3.1426e-04\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 77s 15s/step - loss: 0.0283 - mae: 0.0283 - mse: 0.0017 - val_loss: 0.0186 - val_mae: 0.0186 - val_mse: 3.9293e-04\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 80s 16s/step - loss: 0.0287 - mae: 0.0287 - mse: 0.0017 - val_loss: 0.0066 - val_mae: 0.0066 - val_mse: 7.9305e-05\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 74s 15s/step - loss: 0.0242 - mae: 0.0242 - mse: 0.0015 - val_loss: 0.0064 - val_mae: 0.0064 - val_mse: 7.4314e-05\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 74s 15s/step - loss: 0.0141 - mae: 0.0141 - mse: 3.2278e-04 - val_loss: 0.0066 - val_mae: 0.0066 - val_mse: 6.3657e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb296eda4c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit_onecycle(1e-3, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
